---
title: "Deep Learning at Centro de Informática - Research"
layout: textlay
excerpt: "Deep Learning at Centro de Informática -- Research"
sitemap: false
permalink: /research/
---

# Research projects

Deep Learning is an essential field of Machine Learning based on computer algorithms for data representations at multiple levels of abstraction. These representations involve a hierarchy of features or concepts where higher-level representations are defined from lower-level ones. The same lower-level representations help define higher-level ones. Deep learning uses artificial neural networks with many layers and large datasets to training algorithms on how to solve perceptual problems, such as detecting recognizable concepts in data, translating or understanding natural languages, interpreting information from input data, and more. Deep Artificial Neural Networks have recently won numerous contests in Pattern Recognition and Machine Learning.

The Deep Artificial Neural Networks literature and applications actually represent the best recognition performance in different Pattern Recognition fields, including computer vision, image recognition, speech recognition, natural language processing, text processing, information retrieval, and multimodal information processing.
Despite the significant progress and results, many challenges remain, aspects like large-scale parameter optimization, modeling of temporal data with long-term dependencies, generative modeling, efficient Bayesian inference, multimodal data and models, and learning representations needs more contributions.

Our overarching goal is to gather the recent advances, ongoing developments, and the road that lies ahead of the field of Deep Learning in Artificial Neural Networks. The suggested research areas are, but not restricted to, Restricted Boltzmann Machines and Autoencoders (Unsupervised), Convolutional Neural Networks and Recurrent Neural Networks (Supervised),  Adversarial Ataques and Defenses, Deep (Feed Forward) Neural Networks (Supervised), Neural Turing Machines and Memory Networks (Supervised), Neural Architecture Search, Deep Q-Networks (Reinforcement Learning), Sequence to Sequence: Attention Mechanisms, Neural Machine Translations and Neural Conversational Models (Supervised), Few shot Learning, and 
Generative Adversarial Networks (Unsupervised).